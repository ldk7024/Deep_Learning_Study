{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1-1 \n",
    "- 선형회귀는 데이터를 놓고 가장 잘 설명할 수 있는 선을 분석하는 방법이다. 보통 종속변수와 한개이상의 독립변수와의 선형 상관관계를 분석하는 기법, 여기서 한 개의 설명 변수만 가진다면 단순 선형회귀라고 하고, 두개 이상의 설명변수를 가지면 다중 선형 회귀라고 한다.\n",
    "- 로지스틱 회귀란 선형회귀에서 구하는 직선대신 s자 곡선을 이용하여 분류의 정확도를 구하는 방법, 로지스틱 회귀는 선형회귀와는 다르게 범주형일떄 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1-2\n",
    "- 평균제곱오차 MSE는 말 그대로 오차를 평균과 제곱을 이용해 계산한 것이다. 가정한 모델이 데이터와 얼만큼 차이가 있는지 알아보기 위해 사용하고, 평균제곱오차가 작을 수록 원래의 데이터와 오차가 적은 것이므로 추측한 값의 정확성이 높게됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1-3\n",
    "- 경사하강법이란 기울기를 구하여 기울기가 낮은 쪽으로 계속 이동시켜 최적값에 이를 때까지 반복하는 것 입니다. 함수의 최소값 위치를 찾기위해 cost function의 경사 반대 방향으로 정의한 step size를 가지고 조금씩 움직여가면서 최적의 파라미터를 찾는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1-4\n",
    "- 시그모이드 함수는 s자 처럼 시그모이드 커브 형태를 보이는 함수입니다. 시그모이드 함수는 모든 실수 입력 밧을 0보다 크고 1보다 작은 미분 가능한 수로 변환합니다. 또한 시그모이드 함수의 반환 값은 확률형태이므로 결과를 확률로 받을 때 좋은 함수입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2-1\n",
    "- 퍼셉트론은 perceptrion (인지하는 능력), Neuron (감각 입력 정보를 의미있는 정보로 바꿔주는 뇌의 세포)로 조합된 단어이며, 퍼셉트론은 우리 뇌에 있는 뉴런을 따라해 인공적으로 만든 뉴런입니다.\n",
    "퍼셉트론은 더 나은 결과를 얻기 위해 자신의 결과를 판단해 다음번에는 더 나은 결과를 낼 수 있도록 자기 자신을 수정할 수 있으며, 이러한 퍼셉트론을 묶어놓은 단위가 신경망이다.\n",
    "또한 가중치란 사용자들이 입력하는 값에 대해 중요도를 매기는데, 가중치가 크다는 것은 입력값이 결과를 결정하는 데 있어서 더 중요한 역할을 한다는 뜻 입니다.\n",
    "가중치는 학습에 따라 바뀝니다.\n",
    "바이어스란 각 노드의 활성화 여부를 조절하는 역할을 하는데, 각 노드마다 독립적인 바이어스를 가지고 있으며, 가중치처럼 학습에 의해 바뀌고, 편향이라고도 불립니다. 보통 하나의 뉴런으로 입력된 모든 값을 다 더한 다음에, 최종적으로 출력되는 값을 조절해주는 값에 더해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2-2\n",
    "- XOR 문제란 0,1일때는 True값, 0,0 일때는 False 값을 출력하는 것이 컴퓨터 연산의 가장 기초적인 것인데, 1과 0 0과 1로 이루어진 그래프에 어떠한 방법을 이용해도 XOR문제를 해결하지 못하는 난관에 부딪혔지만, 여러개의 퍼셉트론을 이용하여 XOR 문제를 해결할 수 있습니다. 결론적으로 두개 이상의 퍼셉트론을 한번에 계산하여 평면을 휘어주어 은닉층을 만들어주면 원하는 결과를 얻을 수 있어 다층 퍼셉트론으로 XOR 문제가 해결되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2-3\n",
    "- 오차 역전파 (Back Propagation): 은닉층이 두개 이상일 경우 심층 신경망이라고 하는데, 모든 노드들이 서로 연결되어 있는 구조를 띕니다. 이러한 경우에는 전체식을 미분으로 계산하기 어려운데, 미분으로 계산하기에는 시간이 너무 오래걸립니다. 이를 해결하기 위한 개념이 오차 역전파인데, 오차역전파는 출력 노드들만 미분하고, 앞의 노드들에 전달하여 재사용하는 방법입니다.\n",
    "- 순전파: 입력 데이터를 입력층에서부터 출력층까지 정방향으로 이동시키며 출력 값을 추론해 나가는 과정\n",
    "- 역전파: 출력층에서 발생한 에러를 입력층 쪽으로 전파시키면서 최적의 결과를 학습해 나가는 과정\n",
    "\n",
    "순전파 = 예측\n",
    "역전파 = 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2-4\n",
    "- 기울기 소실 문제란 은닉층이 많은 다층 퍼셉트론에서 은닉층을 많이 이동할 수록 전달되는 오차가 크게 줄어들어 학습이 안되는 현상을 의미합니다. 기울기가 거의 0으로 소멸되어 버리면 학습이 다 이루어지지 않는 상태에서 멈춰버립니다. 이를 해결하는 방법으로는 사라져가는 성질을 갖지 않는 비선형 함수를 활성화 함수 ReLu함수로 선택하면 해결할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2-5\n",
    "- 딥러닝에서 과적합이 발생하는 이유는 학습 데이터가 실제로 존재하는 전체 데이터에 비해 적거나 변수들이 많은 경우에 생길 수 있습니다. 학습 데이터가 적은 경우에는 학습이 잘 된다고 하더라도 실제 정확도를 보장할 수 있습니다. 또한 잘못된 데이터를 사용하는 경우에 과적합이 일어날 수 있는데, 이러한 경우에는 당연하게도 올바른 데이터로 바뀌기 전까지는 과적합이 일어납니다 또한 데이터의 분포가 불균형하게 형성되어 있다면, 과적합이 일어날 수 있습니다. 이러한 과적합은 \n",
    "dropout이나 데이터 확장(증식)을 통해 해결할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2-6\n",
    "- 활성화 함수란 신경망에서 한 노드에 입력값을 다음 노드에 보낼지 말지 결정하는 함수입니다.\n",
    "주로 비선형 함수로 되어 있습니다.\n",
    "- 신경망은 선형회귀와 달리 한 계층의 신호를 다음 계층으로 그대로 전달하지 않고, 비 성형적인 활성화 함수를 거친 후에 전달한다. (선형함수를 사용하면 층을 깊게하는 의미가 줄어들어 층을 쌓는것이 힘들어지기 때문입니다.)\n",
    "- 이렇게 하는 이유는 신경망을 모방하여 사람처럼 사고하는 인공지능 기술을 구현하기 위함\n",
    "- 실제로 비선형의 활성화 함수를 도입한 신경망이 잘 되고 있음.\n",
    "-> 층에 따라 다른 활성화 함수를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 문제 3-1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = da???????????????????\n",
    "y_data = ?????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1e89370c5842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### 문제 3-2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "### 문제 3-2\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번 중간층 활성화 함수 sigmoid\n",
    "\n",
    "# 신경망의 뼈대를 설정\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add (Flatten(input_shape = (28,28)))\n",
    "\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "\n",
    "# 중간층\n",
    "model.add(Dense(500,activation=\"relu\"))   # 하나의 층\n",
    "model.add(Dense(300, activation=\"relu\"))   # 하나의 층\n",
    "model.add(Dense(100, activation=\"relu\"))   # 하나의 층\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(10, activation=\"softmax\"))   \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습/ 평가 방법 설정\n",
    "model.compile(loss =\"categorical_crossentropy\",\n",
    "               optimizer = 'Adam',           \n",
    "               metrics = [\"acc\"]               \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(X_train, \n",
    "              y_train_one_hot,\n",
    "              validation_data = (X_val, y_val_one_hot), \n",
    "              epochs=100,\n",
    "              batch_size = 20,\n",
    "              callbacks = [r_mckp, r_early]\n",
    "              validation_split = 0.25\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
