{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21.07.06_keras 맛보기 (폐암환자 생존예측)",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fbVv69OWVT5SxkixEHFcxvHMnAMQux6e",
      "authorship_tag": "ABX9TyM2non7p7XiSmygf00+LZKn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldk7024/Deep_Learning_Study/blob/main/21_07_06_keras_%EB%A7%9B%EB%B3%B4%EA%B8%B0_(%ED%8F%90%EC%95%94%ED%99%98%EC%9E%90_%EC%83%9D%EC%A1%B4%EC%98%88%EC%B8%A1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUo8lE7vATmm"
      },
      "source": [
        "### 목표\n",
        "- 폐암 환자의 생존을 예측하는 모델을 만들어보자!\n",
        "- 신경망을 활용하여 2진 분류 문제를 해결해보자!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpjyS72vAPTv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyX9O38Cl5T_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "xNO1R1PlAPev",
        "outputId": "b77f1e9f-8ab7-406b-ba3e-d4acbcb8a06a"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/빅데이터4차(딥러닝)/data/ThoraricSurgery.csv\",\n",
        "                  header =None)\n",
        "\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>293</td>\n",
              "      <td>1</td>\n",
              "      <td>3.80</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.88</td>\n",
              "      <td>2.16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>3.19</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>3.98</td>\n",
              "      <td>3.06</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>2.21</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>98</td>\n",
              "      <td>6</td>\n",
              "      <td>3.04</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>369</td>\n",
              "      <td>6</td>\n",
              "      <td>3.88</td>\n",
              "      <td>2.72</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>406</td>\n",
              "      <td>6</td>\n",
              "      <td>5.36</td>\n",
              "      <td>3.96</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>25</td>\n",
              "      <td>8</td>\n",
              "      <td>4.32</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>447</td>\n",
              "      <td>8</td>\n",
              "      <td>5.20</td>\n",
              "      <td>4.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>470 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0   1     2     3   4   5   6   7   ...  10  11  12  13  14  15  16  17\n",
              "0    293   1  3.80  2.80   0   0   0   0  ...  12   0   0   0   1   0  62   0\n",
              "1      1   2  2.88  2.16   1   0   0   0  ...  14   0   0   0   1   0  60   0\n",
              "2      8   2  3.19  2.50   1   0   0   0  ...  11   0   0   1   1   0  66   1\n",
              "3     14   2  3.98  3.06   2   0   0   0  ...  14   0   0   0   1   0  80   1\n",
              "4     17   2  2.21  1.88   0   0   1   0  ...  12   0   0   0   1   0  56   0\n",
              "..   ...  ..   ...   ...  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..\n",
              "465   98   6  3.04  2.40   2   0   0   0  ...  11   0   0   0   1   0  76   0\n",
              "466  369   6  3.88  2.72   1   0   0   0  ...  12   0   0   0   1   0  77   0\n",
              "467  406   6  5.36  3.96   1   0   0   0  ...  12   0   0   0   0   0  62   0\n",
              "468   25   8  4.32  3.20   0   0   0   0  ...  11   0   0   0   0   0  58   1\n",
              "469  447   8  5.20  4.10   0   0   0   0  ...  12   0   0   0   0   0  49   0\n",
              "\n",
              "[470 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg9kZb4VAPho",
        "outputId": "41df1702-7f09-400d-d3ab-ec5ad46c56f8"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(470, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTmjqQJ6CI7b"
      },
      "source": [
        "- 문제, 정답 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEdJqEPNAPkV"
      },
      "source": [
        "# 문제 정답 분리하기\n",
        "X= data.iloc[:,:-1]     # 문제 -> 전체 행\n",
        "y= data.iloc[:,-1]          # 정답"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRrMR8ggAPnX",
        "outputId": "e76c9742-69b4-4566-b5ed-692293924680"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(470, 17)\n",
            "(470,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e765rkdDqu4"
      },
      "source": [
        "- 학습, 평가 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1vIAKFfDqcH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWxfEFqEAmOu"
      },
      "source": [
        "X_train, X_test,y_train, y_test = train_test_split(X,y,\n",
        "                                                   test_size =0.3,\n",
        "                                                   random_state=5\n",
        "                                                                   )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML9R0bpbAmMf",
        "outputId": "5335212f-359f-43ac-d1e6-e511197566ae"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(329, 17)\n",
            "(141, 17)\n",
            "(329,)\n",
            "(141,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4mFzxxdqtz6"
      },
      "source": [
        "Keras를 활용하여 딥러닝 신경망을 구성해보자!\n",
        "- 1. 신경망 구조 설계\n",
        "- 2. 학습/ 평가방법 설정\n",
        "- 3. 학습 + 시각화\n",
        "- 4. 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cn5o8ClAmJm"
      },
      "source": [
        "# 딥러닝을 위한 라이브러리를 임포트\n",
        "from tensorflow.keras import Sequential  # 신경망의 뼈대를 구성\n",
        "from tensorflow.keras.layers import Dense   # 신경망의 층을 구성"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_2lA8QnAmG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35eda77-ac0e-40aa-fece-51c9e025b311"
      },
      "source": [
        "# 신경망의 뼈대를 설정\n",
        "model = Sequential()\n",
        "\n",
        "# 입력층 + 중간층\n",
        "# input_dim : 데이터 특성의 개수\n",
        "# activation: 활성화 함수를 설정 (들어온 자극 (데이터)에 대한 응답여부를 결정하는 함수)\n",
        "model.add(Dense(10,input_dim=17,activation=\"sigmoid\"))\n",
        "\n",
        "# 중간층\n",
        "model.add(Dense(6,activation=\"sigmoid\"))   # 하나의 층\n",
        "model.add(Dense(4, activation=\"sigmoid\"))   # 하나의 층\n",
        "\n",
        "# 출력층\n",
        "# 출력층은 회귀의 활성화 함수(linear 함수, 활성화 함수 생략가능)\n",
        "# 2진 분류 (sigmoid 함수)\n",
        "model.add(Dense(1, activation=\"sigmoid\")) \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 10)                180       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 6)                 66        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4)                 28        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 279\n",
            "Trainable params: 279\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr8EWI5t1RaL"
      },
      "source": [
        "### 활성화 함수: 자극에 대한 반응여부를 결정하는 함수\n",
        "- 회귀: linear (항등함수) -> 신경망에서 도출된 수치값을 그대로 예측에 사용\n",
        "- 분류: 딥러닝은 선형회귀 모델을 기반으로 하고 있기 때문에 도출된 수치 값으로는 분류 문제를 예측하기 힘듬\n",
        "  - 2진분류: sigmoid 함수 (0.5를 기준으로 0또는 1로 분류, 0인지 1인지를 확률 정보를 통해서 예측)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogzhnki71OoS"
      },
      "source": [
        "# 2. 학습/ 평가 방법 설정\n",
        "# binary_crosstentropy : 2진 분류에 사용하는 손실함수 (비용함수)\n",
        "# -> 오차의 평균을 구하는 것은 MSE와 같지만 0~1사이 값으로 변환 후 평균오차를 구하게 되는 방식\n",
        "model.compile (loss =\"binary_crossentropy\",\n",
        "               optimizer = \"SGD\",              # 최적화 함수: 확률적 경사하강법 사용\n",
        "               metrics = [\"acc\"]               # metrics: 평가 방법을 설정 (분류 문제이기 때문에 정확도(acc)를 확인)\n",
        "               )"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcmYOUs3AmEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b05c4e-ed13-4e77-a7c1-3f5a97a82683"
      },
      "source": [
        "h = model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7283 - acc: 0.1459\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6957 - acc: 0.4438\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6668 - acc: 0.8541\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6417 - acc: 0.8541\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6184 - acc: 0.8541\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5987 - acc: 0.8541\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5803 - acc: 0.8541\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5643 - acc: 0.8541\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5500 - acc: 0.8541\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5369 - acc: 0.8541\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5256 - acc: 0.8541\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5151 - acc: 0.8541\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5063 - acc: 0.8541\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4984 - acc: 0.8541\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4910 - acc: 0.8541\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4846 - acc: 0.8541\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4791 - acc: 0.8541\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4733 - acc: 0.8541\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4684 - acc: 0.8541\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4639 - acc: 0.8541\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4598 - acc: 0.8541\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4561 - acc: 0.8541\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4529 - acc: 0.8541\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4500 - acc: 0.8541\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4470 - acc: 0.8541\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4442 - acc: 0.8541\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4418 - acc: 0.8541\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4395 - acc: 0.8541\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4374 - acc: 0.8541\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4357 - acc: 0.8541\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4341 - acc: 0.8541\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4329 - acc: 0.8541\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4315 - acc: 0.8541\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4302 - acc: 0.8541\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4291 - acc: 0.8541\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4279 - acc: 0.8541\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4269 - acc: 0.8541\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4260 - acc: 0.8541\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4252 - acc: 0.8541\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4244 - acc: 0.8541\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4237 - acc: 0.8541\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4231 - acc: 0.8541\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4225 - acc: 0.8541\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4220 - acc: 0.8541\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4216 - acc: 0.8541\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4211 - acc: 0.8541\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4207 - acc: 0.8541\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4203 - acc: 0.8541\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4199 - acc: 0.8541\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4196 - acc: 0.8541\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4194 - acc: 0.8541\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4190 - acc: 0.8541\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4186 - acc: 0.8541\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4184 - acc: 0.8541\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4181 - acc: 0.8541\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4179 - acc: 0.8541\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4178 - acc: 0.8541\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4175 - acc: 0.8541\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4174 - acc: 0.8541\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4173 - acc: 0.8541\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4172 - acc: 0.8541\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4172 - acc: 0.8541\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4170 - acc: 0.8541\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4169 - acc: 0.8541\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4167 - acc: 0.8541\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4166 - acc: 0.8541\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4164 - acc: 0.8541\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4163 - acc: 0.8541\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4163 - acc: 0.8541\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4162 - acc: 0.8541\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4161 - acc: 0.8541\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4161 - acc: 0.8541\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4160 - acc: 0.8541\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4159 - acc: 0.8541\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4158 - acc: 0.8541\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4158 - acc: 0.8541\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4158 - acc: 0.8541\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4157 - acc: 0.8541\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4157 - acc: 0.8541\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4156 - acc: 0.8541\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4156 - acc: 0.8541\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4155 - acc: 0.8541\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4154 - acc: 0.8541\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4154 - acc: 0.8541\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4154 - acc: 0.8541\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4153 - acc: 0.8541\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4153 - acc: 0.8541\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4153 - acc: 0.8541\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4153 - acc: 0.8541\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4153 - acc: 0.8541\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4152 - acc: 0.8541\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4152 - acc: 0.8541\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4152 - acc: 0.8541\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4152 - acc: 0.8541\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4152 - acc: 0.8541\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4151 - acc: 0.8541\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4151 - acc: 0.8541\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4151 - acc: 0.8541\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4151 - acc: 0.8541\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4151 - acc: 0.8541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "HPyAnNyO3R6R",
        "outputId": "d027ae45-5428-4bf9-f1f4-45d3a8f1e62d"
      },
      "source": [
        "# 시각화\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.plot(range(1,101),\n",
        "         h.history['acc'],\n",
        "         label ='acc'\n",
        "         )\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7I9IG3N3nOk",
        "outputId": "4cfbf676-ea7d-47b6-d946-29d766b9766f"
      },
      "source": [
        "# 모델 평가\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4334 - acc: 0.8440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4333949685096741, 0.8439716100692749]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M64Dqjc-3nMF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bpOKkfX5jih"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}