{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "21.07.23_SimpleRNN을 활용하여 단어 예측(hello)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1jbmhotQ3gq8w-G2aa6YE989-NGOzycDX",
      "authorship_tag": "ABX9TyMAjnf/Lxhm8yKmftjhZ00s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldk7024/Deep_Learning_Study/blob/main/21_07_23_SimpleRNN%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%98%EC%97%AC_%EB%8B%A8%EC%96%B4_%EC%98%88%EC%B8%A1(hello).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMDPZVKTkZmK"
      },
      "source": [
        "### 간단한 단어 데이터를 만들어서 RNN의 구조를 익혀보자!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xb8OuBHNwlM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_L59Dq1B7hH"
      },
      "source": [
        "- 글자 하나하나를 단위로 RNN을 사용해보자!\n",
        "- hello, apple, lobby, daddy, bobby"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo6KNdW-Bkww"
      },
      "source": [
        "# 문제 데이터는 hell, appl, lobb, dadd, bobb\n",
        "# 정답 데이터는 o,e,y,y,y\n",
        "\n",
        "# timesteps: 4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MofXZKrBkt_"
      },
      "source": [
        "### 우리의 목표는 앞의 4단어를 통해서 뒤에 나올 1단어를 예측하는 것!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_faXmj_BkrJ"
      },
      "source": [
        "# 원핫인코딩으로 문자를 숫자로 변경\n",
        "# 문제 + 정답의 전체 데이터에서 등장하는 문자는 h,e,l,o,a,p,b,y,d로 9개"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PNqAlq_BkoI"
      },
      "source": [
        "### RNN 데이터의 구조 파악을 위해 직접 원핫인코딩을 해보자!"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qpLf4H_BklP"
      },
      "source": [
        "# 문제 데이터\n",
        "X_train = np.array(\n",
        "    [\n",
        "     [ [1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0] ],   # hell\n",
        "     [ [0,0,0,0,1,0,0,0,0],[0,0,0,0,0,1,0,0,0],[0,0,0,0,0,1,0,0,0],[0,0,1,0,0,0,0,0,0] ],   # appl\n",
        "     [ [0,0,1,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,1,0,0] ],   # lobb\n",
        "     [ [0,0,0,0,0,0,0,0,1],[0,0,0,0,1,0,0,0,0],[0,0,0,0,0,0,0,0,1],[0,0,0,0,0,0,0,0,1] ],   # dadd\n",
        "     [ [0,0,0,0,0,0,1,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,1,0,0] ],   # bobb\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlbHqOLYBkif"
      },
      "source": [
        "# 정답 데이터\n",
        "y_train = np.array(\n",
        "    [\n",
        "     [0,0,0,1,0,0,0,0,0],   # o\n",
        "     [0,1,0,0,0,0,0,0,0],   # e\n",
        "     [0,0,0,0,0,0,0,1,0],   # y\n",
        "     [0,0,0,0,0,0,0,1,0],   # y\n",
        "     [0,0,0,0,0,0,0,1,0]    # y\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJI9srkpBkf3",
        "outputId": "8f92fe40-33dd-4d8b-aedc-a43728277cbe"
      },
      "source": [
        "X_train.shape, y_train.shape\n",
        "# samples (데이터의 수), timesteps(순환 횟수), fetures(데이터의 특성 수 = 원핫인코딩된 레이블 수)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5, 4, 9), (5, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46uP9etmHWM0"
      },
      "source": [
        "- 출력되는 값을 영어 알파벳 전체로 하고 싶다면 26개로 원핫인코딩을 하면 됨\n",
        "- 현재는 RNN을 알아보기 위해 간단히 9개의 단어로만 문제와 정답을 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBXjYf5EHjT0"
      },
      "source": [
        "### RNN 신경망 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD9WobwrGvEt"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQy0n30FSukA"
      },
      "source": [
        "- 입력층은 문제 데이터를 보고, 출력층은 정답 데이터를 보고 결정할 것!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJaqJFQYH0ks",
        "outputId": "767b0056-e0f7-4f8e-82d2-9d2523f3691a"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 입력층 + 중간층\n",
        "# 8개의 뉴런을 가지고 각 뉴런이 4번씩 순환하며 각 순화마다 9개의 숫자가 들어감\n",
        "model.add(SimpleRNN(8,input_shape=(4,9)))\n",
        "\n",
        "# 출력층\n",
        "# 사용되는 단어가 총 9개이고, 그 중에서 정답(다음에 나올 단어)을 찾아내는 것이기 때문에 다중분류\n",
        "model.add(Dense(9,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# RNN은 가중치가 두 종류가 있음 (과거데이터의 가중치, 현재 데이터의 가중치)\n",
        "# 현재데이터의 가중치 -> 9(입력특성) * 8(RNN층의 뉴런수)+ 8(RNN층의 뉴런수)\n",
        "# 과거데이터의 가중치 -> 8(RNN층 뉴런수) * 8(RNN층 뉴런수)\n",
        "# RNN층의 각 뉴런층에 뽑아낸 결과값은 다시 모든 뉴런들에게 과거데이터로 들어가게 됨\n",
        "# 순환횟수와는 상관없이 최종 결과 값에 대한 가중치를 카운트"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 8)                 144       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 9)                 81        \n",
            "=================================================================\n",
            "Total params: 225\n",
            "Trainable params: 225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBMU0sQlQaJC"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer= 'Adam',\n",
        "              metrics=['acc']\n",
        "              )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JThI74GThBB",
        "outputId": "834fa7bd-dc0a-4da1-d2ad-1d9835afc568"
      },
      "source": [
        "h = model.fit(X_train, y_train, epochs=200)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3152 - acc: 0.0000e+00\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3009 - acc: 0.0000e+00\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2866 - acc: 0.0000e+00\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2724 - acc: 0.0000e+00\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2583 - acc: 0.0000e+00\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2442 - acc: 0.0000e+00\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2302 - acc: 0.0000e+00\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2163 - acc: 0.0000e+00\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2024 - acc: 0.0000e+00\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1886 - acc: 0.2000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1749 - acc: 0.2000\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1612 - acc: 0.2000\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1476 - acc: 0.2000\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1340 - acc: 0.2000\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1205 - acc: 0.2000\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1071 - acc: 0.2000\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0937 - acc: 0.2000\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0804 - acc: 0.2000\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0671 - acc: 0.4000\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0539 - acc: 0.4000\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0407 - acc: 0.4000\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0276 - acc: 0.4000\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0145 - acc: 0.4000\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0015 - acc: 0.4000\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9886 - acc: 0.4000\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9756 - acc: 0.4000\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9628 - acc: 0.4000\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9499 - acc: 0.4000\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9371 - acc: 0.4000\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9243 - acc: 0.4000\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9116 - acc: 0.4000\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8989 - acc: 0.4000\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8862 - acc: 0.4000\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8736 - acc: 0.4000\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8609 - acc: 0.4000\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8483 - acc: 0.4000\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8358 - acc: 0.4000\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8232 - acc: 0.4000\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8107 - acc: 0.4000\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7982 - acc: 0.6000\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7857 - acc: 0.6000\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7732 - acc: 0.6000\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7607 - acc: 0.6000\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7482 - acc: 0.6000\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7358 - acc: 0.6000\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7233 - acc: 0.6000\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7109 - acc: 0.6000\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6985 - acc: 0.6000\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6860 - acc: 0.6000\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6736 - acc: 0.6000\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6612 - acc: 0.8000\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6488 - acc: 0.8000\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6364 - acc: 0.8000\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6240 - acc: 0.8000\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6115 - acc: 0.8000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5991 - acc: 0.8000\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5867 - acc: 0.8000\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5743 - acc: 0.8000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5619 - acc: 0.8000\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5494 - acc: 0.8000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5370 - acc: 0.8000\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5246 - acc: 0.8000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5121 - acc: 0.8000\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4997 - acc: 0.8000\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4872 - acc: 0.8000\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4748 - acc: 0.8000\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4623 - acc: 0.8000\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4499 - acc: 0.8000\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4375 - acc: 0.8000\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4250 - acc: 0.8000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4126 - acc: 0.8000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4002 - acc: 1.0000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3878 - acc: 1.0000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3753 - acc: 1.0000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3629 - acc: 1.0000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3506 - acc: 1.0000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3382 - acc: 1.0000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3258 - acc: 1.0000\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3135 - acc: 1.0000\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3012 - acc: 1.0000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2889 - acc: 1.0000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2767 - acc: 1.0000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2644 - acc: 1.0000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2522 - acc: 1.0000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2401 - acc: 1.0000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2280 - acc: 1.0000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2159 - acc: 1.0000\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2038 - acc: 1.0000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1918 - acc: 1.0000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1799 - acc: 1.0000\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1680 - acc: 1.0000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1562 - acc: 1.0000\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1444 - acc: 1.0000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1326 - acc: 1.0000\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1210 - acc: 1.0000\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1094 - acc: 1.0000\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0979 - acc: 1.0000\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0864 - acc: 1.0000\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0750 - acc: 1.0000\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0637 - acc: 1.0000\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0525 - acc: 1.0000\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0414 - acc: 1.0000\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0303 - acc: 1.0000\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0193 - acc: 1.0000\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0084 - acc: 1.0000\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9977 - acc: 1.0000\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9870 - acc: 1.0000\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9764 - acc: 1.0000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9658 - acc: 1.0000\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9554 - acc: 1.0000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9451 - acc: 1.0000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9349 - acc: 1.0000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9248 - acc: 1.0000\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9148 - acc: 1.0000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9049 - acc: 1.0000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8951 - acc: 1.0000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8854 - acc: 1.0000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8758 - acc: 1.0000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8664 - acc: 1.0000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8570 - acc: 1.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8477 - acc: 1.0000\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8386 - acc: 1.0000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8295 - acc: 1.0000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8206 - acc: 1.0000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8117 - acc: 1.0000\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8030 - acc: 1.0000\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7944 - acc: 1.0000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7858 - acc: 1.0000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7774 - acc: 1.0000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7691 - acc: 1.0000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7609 - acc: 1.0000\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7528 - acc: 1.0000\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7448 - acc: 1.0000\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7368 - acc: 1.0000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7290 - acc: 1.0000\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7213 - acc: 1.0000\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7137 - acc: 1.0000\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7062 - acc: 1.0000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6987 - acc: 1.0000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6914 - acc: 1.0000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6841 - acc: 1.0000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6770 - acc: 1.0000\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6699 - acc: 1.0000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6630 - acc: 1.0000\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6561 - acc: 1.0000\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6493 - acc: 1.0000\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6426 - acc: 1.0000\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6359 - acc: 1.0000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6294 - acc: 1.0000\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6230 - acc: 1.0000\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6166 - acc: 1.0000\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6103 - acc: 1.0000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6041 - acc: 1.0000\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5979 - acc: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5919 - acc: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5859 - acc: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5800 - acc: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5742 - acc: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5684 - acc: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5627 - acc: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5571 - acc: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5516 - acc: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5461 - acc: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5407 - acc: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5354 - acc: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5301 - acc: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5249 - acc: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5198 - acc: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5147 - acc: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5097 - acc: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5048 - acc: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4999 - acc: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4951 - acc: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4904 - acc: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4857 - acc: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4810 - acc: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4765 - acc: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4719 - acc: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4675 - acc: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4631 - acc: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4587 - acc: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4544 - acc: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4502 - acc: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4460 - acc: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4419 - acc: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4378 - acc: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4338 - acc: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4298 - acc: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4258 - acc: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4220 - acc: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4181 - acc: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - acc: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - acc: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4069 - acc: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4033 - acc: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3997 - acc: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3961 - acc: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3926 - acc: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3891 - acc: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3857 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "nKf46WI2ZJP1",
        "outputId": "8e9fe7c5-a949-4b7c-9a35-4acff44c6ea3"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(h.history['acc'],\n",
        "         label='acc'\n",
        "          )\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zihv8cdTZwZm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp60iSzgZJFm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}